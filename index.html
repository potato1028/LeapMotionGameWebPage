<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>심기준 | AI TRPG 포트폴리오</title>
    <!-- Tailwind CSS 로드 -->
    <script src="https://cdn.tailwindcss.com"></script>
    <!-- Google Inter 폰트 로드 -->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        /* Inter 폰트 기본 적용 */
        body {
            font-family: 'Inter', sans-serif;
        }
        /* 다크 모드 기본 스타일 */
        html {
            color-scheme: dark;
        }
    </style>
</head>
<body class="bg-slate-900 text-gray-100 antialiased">

    <!-- 전체 컨테이너 -->
    <div class="max-w-4xl mx-auto p-6 md:p-12">

        <!-- 1. 기본 정보 (헤더) -->
        <header class="flex flex-col md:flex-row items-center md:items-start space-y-6 md:space-y-0 md:space-x-10 mb-16">
            <!-- 프로필 이미지 (플레이스홀더) -->
            <img 
                src="https://placehold.co/160x160/1e293b/94a3b8?text=KSJ" 
                alt="심기준 프로필 이미지" 
                class="w-40 h-40 rounded-full border-4 border-slate-700 shadow-lg flex-shrink-0"
            >
            
            <div class="text-center md:text-left">
                <!-- 이름 -->
                <h1 class="text-4xl md:text-5xl font-bold text-white mb-2">심기준</h1>
                
                <!-- 한 줄 소개 -->
                <p class="text-xl md:text-2xl text-indigo-400 font-medium mb-4">
                    로컬 LLM과 규칙 엔진을 결합하여 1인 TRPG 경험을 구현하는 개발자
                </p>

                <!-- 연락처 링크 (GitHub, Email) -->
                <div class="flex justify-center md:justify-start space-x-4">
                    <a href="https://github.com/username" target="_blank" rel="noopener noreferrer" class="flex items-center space-x-2 text-slate-300 hover:text-indigo-400 transition-colors duration-200">
                        <!-- GitHub 아이콘 SVG -->
                        <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path fill-rule="evenodd" d="M12 2C6.477 2 2 6.477 2 12c0 4.418 2.865 8.165 6.839 9.49.5.092.682-.217.682-.483 0-.237-.009-.868-.014-1.703-2.782.605-3.369-1.343-3.369-1.343-.454-1.158-1.11-1.466-1.11-1.466-.908-.62.069-.608.069-.608 1.003.07 1.531 1.032 1.531 1.032.892 1.53 2.341 1.088 2.91.832.092-.647.35-1.088.636-1.338-2.22-.253-4.555-1.113-4.555-4.951 0-1.093.39-1.988 1.03-2.688-.103-.253-.446-1.272.098-2.65 0 0 .84-.27 2.75 1.026A9.564 9.564 0 0112 6.84c.85.004 1.705.115 2.504.337 1.909-1.296 2.747-1.026 2.747-1.026.546 1.379.202 2.398.1 2.65.64.7 1.028 1.595 1.028 2.688 0 3.848-2.339 4.695-4.566 4.943.359.309.678.92.678 1.855 0 1.338-.012 2.419-.012 2.747 0 .268.18.58.688.482A10.001 10.001 0 0022 12c0-5.523-4.477-10-10-10z" clip-rule="evenodd"></path></svg>
                        <span>GitHub</span>
                    </a>
                    <a href="mailto:email@example.com" class="flex items-center space-x-2 text-slate-300 hover:text-indigo-400 transition-colors duration-200">
                        <!-- 이메일 아이콘 SVG -->
                        <svg class="w-5 h-5" fill="currentColor" viewBox="0 0 24 24" aria-hidden="true"><path d="M1.75 3h20.5c.966 0 1.75.784 1.75 1.75v14.5A1.75 1.75 0 0122.25 21H1.75A1.75 1.75 0 010 19.25V4.75C0 3.784.784 3 1.75 3zM2.5 19.5h19V7.11l-9.33 6.315a1.25 1.25 0 01-1.34 0L2.5 7.11V19.5zM3.404 5l8.596 5.807L20.596 5H3.404z"></path></svg>
                        <span>Email</span>
                    </a>
                </div>
            </div>
        </header>

        <!-- 메인 콘텐츠 영역 -->
        <main class="space-y-16">
        
            <!-- 1.5. 상세 소개 (About Me) -->
            <section>
                <h2 class="text-3xl font-bold text-white mb-6 border-b border-slate-700 pb-2">
                    About Me
                </h2>
                <div class="space-y-4 text-slate-300 text-lg leading-relaxed">
                    <p>
                        저는 AI 기술, 특히 로컬 LLM을 활용해 새로운 사용자 경험을 만드는 데 매력을 느끼는 개발자입니다. TRPG의 가장 큰 진입 장벽인 '게임 마스터(GM)의 부재' 문제를 기술로 해결하고자 이 프로젝트를 시작했습니다.
                    </p>
                    <p>
                        Ollama와 Python을 기반으로, AI의 창의적인 서사 생성 능력과 Python의 엄격한 규칙 관리 능력을 명확히 분리하는 하이브리드 아키텍처를 설계하고 구현하는 과정에 집중했습니다. 이 프로젝트를 통해 복잡한 문제를 분해하고, AI 툴 호출(Tool Calling)과 같은 최신 기술을 적용하여 실제 작동하는 프로토타입을 완성한 시스템 설계 역량을 보여주고자 합니다.
                    </p>
                </div>
            </section>

            <!-- 2. 전체 기술 스택 (Skills) -->
            <section>
                <h2 class="text-3xl font-bold text-white mb-6 border-b border-slate-700 pb-2">
                    Skills
                </h2>
                <div class="flex flex-wrap gap-3">
                    <span class="bg-indigo-900 text-indigo-200 px-4 py-1.5 rounded-full text-sm font-medium">Python</span>
                    <span class="bg-indigo-900 text-indigo-200 px-4 py-1.5 rounded-full text-sm font-medium">Ollama</span>
                    <span class="bg-indigo-900 text-indigo-200 px-4 py-1.5 rounded-full text-sm font-medium">AI Tool Calling</span>
                    <span class="bg-indigo-900 text-indigo-200 px-4 py-1.5 rounded-full text-sm font-medium">JSON</span>
                    <span class="bg-slate-700 text-slate-200 px-4 py-1.5 rounded-full text-sm font-medium">Llama 3.1 (8B)</span>
                    <span class="bg-slate-700 text-slate-200 px-4 py-1.5 rounded-full text-sm font-medium">Qwen 2.5 (7B)</span>
                    <span class="bg-slate-700 text-slate-200 px-4 py-1.5 rounded-full text-sm font-medium">openai (Python)</span>
                    <span class="bg-slate-700 text-slate-200 px-4 py-1.5 rounded-full text-sm font-medium">google-generativeai</span>
                </div>
            </section>

            <!-- 3. 프로젝트 상세 -->
            <section>
                <h2 class="text-3xl font-bold text-white mb-4">
                    Project: <span class="text-indigo-400">AI 기반 TRPG 진행 시스템</span>
                </h2>

                <!-- 프로젝트 카드 -->
                <div class="bg-slate-800 rounded-lg shadow-xl overflow-hidden">
                    
                    <!-- 문제 정의 -->
                    <div class="p-6 md:p-8 border-b border-slate-700">
                        <h3 class="text-xl font-semibold text-white mb-3">[ 문제 정의 ]</h3>
                        <p class="text-slate-300 leading-relaxed">
                            TRPG(Tabletop Role-Playing Game)는 게임 마스터(GM)의 숙련도와 참여가 필수적이라 진입 장벽이 높습니다. GM이 없어도 AI가 GM 역할을 자동화하여, 누구나 혼자서도 TRPG의 핵심 재미인 '자유로운 스토리'를 즐길 수 있는 시스템을 만드는 것이 목표였습니다.
                        </p>
                    </div>

                    <!-- 아키텍처/설계 -->
                    <div class="p-6 md:p-8 border-b border-slate-700">
                        <h3 class="text-xl font-semibold text-white mb-3">[ 아키텍처 / 설계 ]</h3>
                        <p class="text-slate-300 leading-relaxed mb-4">
                            AI(LLM)의 서사/묘사 능력과 Python의 수치/규칙 계산을 명확히 분리하는 하이브리드 아키텍처를 채택했습니다. AI는 '스토리텔러' 역할만, Python은 '심판' 역할만 수행합니다.
                            <br><br>
                            로컬 PC에서 Ollama를 서버로 구동하고, Python의 `openai` 라이브러리를 통해 AI(LLM)가 Python의 `RulesEngine` 클래스 함수를 직접 호출(`tool_call`)하도록 설계했습니다. 모든 데이터는 JSON 포맷으로 교환됩니다.
                        </p>
                        <!-- 아키텍처 다이어그램 (텍스트 기반 설명) -->
                        <div class="mt-4 p-4 bg-slate-900 rounded-md border border-slate-700">
                            <p class="text-slate-400 font-mono text-sm"></p>
                        </div>
                    </div>

                    <!-- 핵심 기능 -->
                    <div class="p-6 md:p-8 border-b border-slate-700 space-y-6">
                        <h3 class="text-xl font-semibold text-white mb-3">[ 핵심 기능 ]</h3>
                        
                        <!-- 기능 1 -->
                        <div>
                            <h4 class="text-lg font-semibold text-indigo-400 mb-2">AI 툴 호출(Tool Call) 기반의 규칙 엔진 연동</h4>
                            <p class="text-slate-300 leading-relaxed">
                                Python으로 `RulesEngine` 클래스를 구현하고, `roll_check`, `apply_damage`, `use_item` 등 핵심 규칙 함수를 정의했습니다. 플레이어의 입력(예: "함정을 살핀다")을 받은 AI(Llama 3.1)가 상황을 인지하고, Python의 `roll_check(skill_or_stat='perception', ...)` 함수를 툴 호출로 스스로 실행하도록 구현했습니다. 엔진은 판정 결과를 데이터(dict/JSON)로 AI에게 반환합니다.
                            </p>
                        </div>

                        <!-- 기능 2 -->
                        <div>
                            <h4 class="text-lg font-semibold text-indigo-400 mb-2">로컬 LLM 비교 테스트 (논리 vs 서사)</h4>
                            <p class="text-slate-300 leading-relaxed">
                                프로토타입의 핵심인 '자연스러운 진행'을 위해 두 가지 로컬 LLM을 테스트했습니다. <strong>Llama 3.1 (8B)</strong>은 툴 호출(논리) 성능은 뛰어났으나 한국어 서사가 어색했습니다(예: `seem을 이치들이...`). 반면 <strong>Qwen 2.5 (7B)</strong>는 한국어 구사력을 기대했으나 툴 호출을 실패하고 서사 품질도 낮았습니다. 이를 통해 로컬 8B급 모델의 명확한 한계를 파악했습니다.
                            </p>
                        </div>
                    </div>
                    
                    <!-- 나의 역할 -->
                    <div class="p-6 md:p-8 border-b border-slate-700">
                        <h3 class="text-xl font-semibold text-white mb-3">[ 나의 역할 및 기여 ]</h3>
                        <ul class="list-disc list-outside space-y-2 pl-5 text-slate-300">
                            <li>AI-규칙 엔진 하이브리드 아키텍처 설계</li>
                            <li>Python 기반 `RulesEngine` 클래스 및 핵심 판정 로직(`roll_check` 등) 구현</li>
                            <li>Ollama 및 `openai` 라이브러리를 사용한 로컬 LLM 연동 및 툴 호출(Tool Calling) 구현 (`trpg_local.py`)</li>
                            <li>Gemini, GPT-4o 등 API 기반 모델과 로컬 모델(Llama, Qwen)의 성능 및 적용 방안 비교 분석</li>
                        </ul>
                    </div>
                    
                    <!-- 결과 및 성과 -->
                    <div class="p-6 md:p-8 border-b border-slate-700">
                        <h3 class="text-xl font-semibold text-white mb-3">[ 결과 및 성과 ]</h3>
                        <ul class="list-disc list-outside space-y-2 pl-5 text-slate-300">
                            <li>Ollama(Llama 3.1 8B) 기반으로 AI GM의 툴 호출 기능이 작동하는 **로컬 프로토타입(`trpg_local.py`) 구현에 성공**함.</li>
                            <li>AI가 서사를, Python이 규칙을 담당하는 기획서의 핵심 아키텍처가 기술적으로 **실현 가능함을 검증**함.</li>
                        </ul>
                    </div>

                    <!-- 회고 -->
                    <div class="p-6 md:p-8 bg-slate-800/50 rounded-b-lg">
                        <h3 class="text-xl font-semibold text-white mb-4">[ 회고 (Lessons Learned) ]</h3>
                        <div class="space-y-4">
                            <div>
                                <h4 class="font-semibold text-indigo-400">배운 점</h4>
                                <p class="text-slate-300">
                                    로컬 LLM(8B급)은 **논리적 툴 호출 성능(Llama 3.1)**과 **자연스러운 한국어 구사 능력(Qwen 2.5)**이 비례하지 않음을 명확히 파악했습니다. 현재 사양(32GB RAM, GPU VRAM 부족)에서는 '어색한 한국어'를 감수하고 '기능 구현'에 집중하는 실용적인 트레이드오프가 필요함을 배웠습니다.
                                </p>
                            </div>
                            <div>
                                <h4 class="font-semibold text-indigo-400">개선점</h4>
                                <p class="text-slate-300">
                                    현재 8B 모델은 **응답 속도가 느리고 한국어 서사가 매우 어색**한 치명적인 한계가 있습니다. 향후 GPT-4o 등 고성능 유료 API를 연동하여 '품질'을 확보하거나, 70B급 로컬 모델을 구동할 수 있는 고사양 하드웨어(고용량 VRAM) 도입을 고려하고 싶습니다.
                                </p>
                            </div>
                        </div>
                    </div>

                </div>
            </section>

        </main>
        
        <!-- 꼬리말 -->
        <footer class="text-center mt-16 text-slate-500 text-sm">
            <p>© 2025 심기준. All rights reserved.</p>
        </footer>

    </div>

</body>
</html>
